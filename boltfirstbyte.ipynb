{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "LZgEYy6qmJR_",
        "outputId": "ee74197b-9985-4f85-a6e7-e29e6695b3aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/flexfield_fitness.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c509655bf57b>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mchefmeal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/chefsmeal.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflexField\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcareboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpulsegear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/flexfield_fitness.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd                                                       # data manipulation and analysis\n",
        "import numpy as np                                                        # numerical computations and array operations\n",
        "import seaborn as sns                                                     # statistical data visualization\n",
        "import matplotlib.pyplot as plt                                           # creating plots and visualizations\n",
        "from sklearn.model_selection import train_test_split, cross_val_score     # splitting data and cross-validation\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder           # preprocessing tools for scaling and encoding\n",
        "from sklearn.impute import SimpleImputer                                  # preprossessing tools for handling missing values\n",
        "from sklearn.linear_model import LinearRegression                         # regression analysis\n",
        "import tensorflow as tf                                                   # neural network\n",
        "from sklearn.neighbors import KNeighborsRegressor                         # knn model\n",
        "from sklearn.metrics import mean_squared_error                            # used for model evaluation\n",
        "from google.colab import drive\n",
        "import statsmodels.api as sm\n",
        "drive.mount('/content/drive')\n",
        "#drive.mount('/content/drive')\n",
        "flexField = '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/flexfield_fitness.xlsx'\n",
        "careboost = '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/coreboost.xlsx'\n",
        "pulsegear = '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/pulsegear.xlsx'\n",
        "chefmeal = '/content/drive/My Drive/MBA_UBC_2024/First-Byte/final/chefsmeal.xlsx'\n",
        "\n",
        "df1 = pd.read_excel(flexField)\n",
        "df2 = pd.read_excel(careboost)\n",
        "df3 = pd.read_excel(pulsegear)\n",
        "df4 = pd.read_excel(chefmeal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0wY11HeySDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df2.isnull().sum())\n",
        "\n",
        "# Drop missing values or fill them\n",
        "df2 = df2.dropna()\n",
        "# Check for duplicate Customer IDs\n",
        "duplicates = df2[df2.duplicated(subset=['Customer ID'], keep=False)]\n",
        "\n",
        "# Print duplicate entries (if any)\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "print(\"Missing values in each column:\\n\", df2.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if necessary)\n",
        "df2_cleaned = df2.dropna()\n",
        "\n",
        "# Optionally, fill missing values\n",
        "# df_filled = df.fillna(method='ffill')  # Forward fill"
      ],
      "metadata": {
        "id": "nHYoNwh8oHt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Fitness Goal and Preferred Sports Drink Type\n",
        "grouped_df2 = df2_cleaned.groupby(['Fitness Goal', 'Preferred Sports Drink Type'])['Average Weekly Consumption (Bottles)'].mean().reset_index()\n",
        "\n",
        "# Display grouped summary\n",
        "print(\"Grouped Consumption:\\n\", grouped_df2)\n",
        "\n",
        "# Visualize the average weekly consumption by fitness goals and preferred sports drinks\n",
        "sns.barplot(data=grouped_df2, x='Preferred Sports Drink Type', y='Average Weekly Consumption (Bottles)', hue='Fitness Goal')\n",
        "plt.title('Average Weekly Consumption by Drink Type and Fitness Goal')\n",
        "plt.ylabel('Average Weekly Consumption (Bottles)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4EUHGNrNpLQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables into dummy variables\n",
        "df2_encoded = pd.get_dummies(df2_cleaned, columns=['Gender', 'Fitness Goal', 'Preferred Sports Drink Type'], drop_first=True)\n",
        "\n",
        "# Define the dependent (y) and independent (X) variables\n",
        "X = df2_encoded.drop(columns=['Average Weekly Consumption (Bottles)', 'Customer ID'])\n",
        "y = df2_encoded['Average Weekly Consumption (Bottles)']\n",
        "\n",
        "# Convert all columns in X to numeric, coerce errors to NaN\n",
        "# This addresses the potential 'object' dtype issue\n",
        "for col in X.columns:\n",
        "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# Impute NaN values with the mean (or another suitable strategy)\n",
        "imputer = SimpleImputer(strategy='mean') # Using SimpleImputer to fill NaN\n",
        "X = imputer.fit_transform(X)\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Display the model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "bKWm7QhopeRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of Hours at Gym vs. Weekly Consumption, colored by Fitness Goal\n",
        "sns.lmplot(data=df2_cleaned, x='Hours at Gym (per week)', y='Average Weekly Consumption (Bottles)', hue='Fitness Goal', aspect=2)\n",
        "plt.title('Weekly Consumption vs. Hours at Gym (by Fitness Goal)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1JIv0wXVqg66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Preferred Sports Drink Type and sum the Average Weekly Consumption\n",
        "most_sold_product = df2_cleaned.groupby('Preferred Sports Drink Type')['Average Weekly Consumption (Bottles)'].sum().reset_index()\n",
        "\n",
        "# Sort by the highest consumption to find the most sold product\n",
        "most_sold_product = most_sold_product.sort_values(by='Average Weekly Consumption (Bottles)', ascending=False)\n",
        "\n",
        "# Display the most sold product\n",
        "print(\"Most Sold Products (Sports Drinks) by Total Consumption:\\n\", most_sold_product)\n",
        "\n",
        "# Visualize the most sold product\n",
        "sns.barplot(data=most_sold_product, x='Preferred Sports Drink Type', y='Average Weekly Consumption (Bottles)')\n",
        "plt.title('Total Consumption of Each Sports Drink Type')\n",
        "plt.ylabel('Total Weekly Consumption (Bottles)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8sDAh-L2q9UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by both Fitness Goal and Preferred Sports Drink Type, and sum the total consumption\n",
        "fitness_goal_consumption = df2_cleaned.groupby(['Fitness Goal', 'Preferred Sports Drink Type'])['Average Weekly Consumption (Bottles)'].sum().reset_index()\n",
        "\n",
        "# Sort by highest consumption per Fitness Goal and Drink Type\n",
        "fitness_goal_consumption = fitness_goal_consumption.sort_values(by='Average Weekly Consumption (Bottles)', ascending=False)\n",
        "\n",
        "# Display the result\n",
        "print(\"Total Consumption by Fitness Goal and Drink Type:\\n\", fitness_goal_consumption)\n",
        "\n",
        "# Visualize the consumption based on fitness goal and drink type\n",
        "sns.barplot(data=fitness_goal_consumption, x='Preferred Sports Drink Type', y='Average Weekly Consumption (Bottles)', hue='Fitness Goal')\n",
        "plt.title('Total Consumption by Fitness Goal and Preferred Drink')\n",
        "plt.ylabel('Total Weekly Consumption (Bottles)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b0Zb_7L-rIBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate Customer IDs\n",
        "duplicates = df3[df3.duplicated(subset=['Customer ID'], keep=False)]\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "missing_values = df3.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "\n",
        "\n",
        "# Check for missing values\n",
        "print(df3.isnull().sum())\n",
        "\n",
        "# Drop missing values or fill them\n",
        "df3 = df3.dropna()\n",
        "# Check for duplicate Customer IDs\n",
        "duplicates = df3[df3.duplicated(subset=['Customer ID'], keep=False)]\n",
        "\n",
        "# Print duplicate entries (if any)\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "print(\"Missing values in each column:\\n\", df3.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if necessary)\n",
        "df3_cleaned = df3.dropna()\n",
        "\n",
        "\n",
        "\n",
        "# Group by Fitness Goal, Type of Apparel Purchased, and Purchase Channel to find total annual spend\n",
        "grouped_consumption = df3_cleaned.groupby(['Fitness Goal', 'Type of Apparel Purchased', 'Primary Apparel Purchase Channel'])['Average Spend on Apparel ($/year)'].sum().reset_index()\n",
        "\n",
        "# Display grouped summary\n",
        "print(\"Grouped Consumption by Fitness Goal, Apparel Type, and Purchase Channel:\\n\", grouped_consumption)\n",
        "\n",
        "# Visualize the grouped consumption\n",
        "sns.barplot(data=grouped_consumption, x='Type of Apparel Purchased', y='Average Spend on Apparel ($/year)', hue='Fitness Goal')\n",
        "plt.title('Total Apparel Spend by Fitness Goal and Apparel Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend ($/year)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f6IhhdaPrWWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables into dummy variables\n",
        "df3_encoded = pd.get_dummies(df3_cleaned, columns=['Gender', 'Fitness Goal', 'Type of Apparel Purchased', 'Primary Apparel Purchase Channel'], drop_first=True)\n",
        "\n",
        "# Check the first few rows of the encoded data\n",
        "print(df3_encoded.head())\n",
        "# Define the dependent variable (y) and independent variables (X)\n",
        "X = df3_encoded.drop(columns=['Average Spend on Apparel ($/year)', 'Customer ID'])\n",
        "y = df3_encoded['Average Spend on Apparel ($/year)']\n",
        "\n",
        "# Convert all columns in X to numeric dtype, coercing errors to NaN\n",
        "# Explicitly specify dtype as float\n",
        "X = X.astype(float)\n",
        "\n",
        "# Drop rows with NaN values after conversion (if any)\n",
        "X = X.dropna()\n",
        "\n",
        "# Align y with X after dropping rows (if any)\n",
        "y = y[X.index]\n",
        "\n",
        "# Add a constant to the independent variables for the intercept\n",
        "X = sm.add_constant(X)\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Display the regression summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "FKLg3oceuN7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Type of Apparel Purchased to find the total spend on each type\n",
        "most_sold_apparel = df3_cleaned.groupby('Type of Apparel Purchased')['Average Spend on Apparel ($/year)'].sum().reset_index()\n",
        "\n",
        "# Sort by the highest total spend to find the most sold apparel type\n",
        "most_sold_apparel = most_sold_apparel.sort_values(by='Average Spend on Apparel ($/year)', ascending=False)\n",
        "\n",
        "# Display the most sold apparel type\n",
        "print(\"Most Sold Apparel Type by Total Spend:\\n\", most_sold_apparel)\n",
        "\n",
        "# Visualize the most sold apparel type\n",
        "sns.barplot(data=most_sold_apparel, x='Type of Apparel Purchased', y='Average Spend on Apparel ($/year)')\n",
        "plt.title('Most Sold Apparel Type by Total Spend')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend ($/year)')\n",
        "plt.show()\n",
        "# Group by Fitness Goal and Type of Apparel Purchased to find the total spend per fitness goal\n",
        "fitness_goal_apparel_spend = df3_cleaned.groupby(['Fitness Goal', 'Type of Apparel Purchased'])['Average Spend on Apparel ($/year)'].sum().reset_index()\n",
        "\n",
        "# Sort by the highest total spend per fitness goal and apparel type\n",
        "fitness_goal_apparel_spend = fitness_goal_apparel_spend.sort_values(by='Average Spend on Apparel ($/year)', ascending=False)\n",
        "\n",
        "# Display the fitness goal and apparel type spending\n",
        "print(\"Total Spend by Fitness Goal and Apparel Type:\\n\", fitness_goal_apparel_spend)\n",
        "\n",
        "# Visualize the fitness goal and apparel type spending\n",
        "sns.barplot(data=fitness_goal_apparel_spend, x='Type of Apparel Purchased', y='Average Spend on Apparel ($/year)', hue='Fitness Goal')\n",
        "plt.title('Fitness Goal vs Apparel Type Spend')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend ($/year)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dHeezFx_vs3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of entries for each fitness goal to see who is buying the most apparel\n",
        "apparel_purchases_by_fitness_goal = df3_cleaned['Fitness Goal'].value_counts().reset_index()\n",
        "apparel_purchases_by_fitness_goal.columns = ['Fitness Goal', 'Total Purchases']\n",
        "\n",
        "# Display who is buying the most apparel based on fitness goal\n",
        "print(\"Total Apparel Purchases by Fitness Goal:\\n\", apparel_purchases_by_fitness_goal)\n",
        "\n",
        "# Visualize the total purchases by fitness goal\n",
        "sns.barplot(data=apparel_purchases_by_fitness_goal, x='Fitness Goal', y='Total Purchases')\n",
        "plt.title('Total Apparel Purchases by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Purchases')\n",
        "plt.show()\n",
        "\n",
        "# Group by Fitness Goal and sum the Average Spend to find who is spending the most\n",
        "apparel_spending_by_fitness_goal = df3_cleaned.groupby('Fitness Goal')['Average Spend on Apparel ($/year)'].sum().reset_index()\n",
        "\n",
        "# Sort by the highest spenders\n",
        "apparel_spending_by_fitness_goal = apparel_spending_by_fitness_goal.sort_values(by='Average Spend on Apparel ($/year)', ascending=False)\n",
        "\n",
        "# Display who is spending the most based on fitness goal\n",
        "print(\"Total Apparel Spending by Fitness Goal:\\n\", apparel_spending_by_fitness_goal)\n",
        "\n",
        "# Visualize the total spending by fitness goal\n",
        "sns.barplot(data=apparel_spending_by_fitness_goal, x='Fitness Goal', y='Average Spend on Apparel ($/year)')\n",
        "plt.title('Total Apparel Spending by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend ($/year)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "082oToI8vv7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_BE70N1m6yol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df4.isnull().sum())\n",
        "\n",
        "# Drop missing values or fill them\n",
        "df4 = df4.dropna()\n",
        "# Check for duplicate Customer IDs\n",
        "duplicates = df4[df4.duplicated(subset=['Customer ID'], keep=False)]\n",
        "\n",
        "# Print duplicate entries (if any)\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "print(\"Missing values in each column:\\n\", df4.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if necessary)\n",
        "df4_cleaned = df4.dropna()\n",
        "\n",
        "# Optionally, fill missing values\n",
        "# df_filled = df.fillna(method='ffill')  # Forward fill"
      ],
      "metadata": {
        "id": "-Y7BJtCbwoPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Fitness Goal, Dietary Preferences, and find total Average Spend per Meal Order\n",
        "grouped_consumption = df4_cleaned.groupby(['Fitness Goal', 'Dietary Preferences'])['Average Spend per Meal Order'].sum().reset_index()\n",
        "\n",
        "# Display grouped summary\n",
        "print(\"Grouped Spend per Meal by Fitness Goal and Dietary Preferences:\\n\", grouped_consumption)\n",
        "\n",
        "# Visualize the grouped spending per meal order\n",
        "sns.barplot(data=grouped_consumption, x='Dietary Preferences', y='Average Spend per Meal Order', hue='Fitness Goal')\n",
        "plt.title('Average Spend per Meal by Fitness Goal and Dietary Preferences')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend per Meal Order')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ZKQBXCfyeSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables (like Dietary Preferences and Fitness Goal) into dummy variables\n",
        "df4_encoded = pd.get_dummies(df4_cleaned, columns=['Gender', 'Fitness Goal', 'Dietary Preferences'], drop_first=True)\n",
        "\n",
        "# Check the first few rows of the encoded data\n",
        "print(df4_encoded.head())\n"
      ],
      "metadata": {
        "id": "aDJtO_slyl2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dependent variable (y) and independent variables (X)\n",
        "X = df4_encoded.drop(columns=['Average Spend per Meal Order', 'Customer ID'])  # Adjust columns as needed\n",
        "y = df4_encoded['Average Spend per Meal Order']\n",
        "\n",
        "# Convert all columns in X to numeric if possible\n",
        "# Errors='coerce' will replace any values that cannot be converted to numeric with NaN\n",
        "for col in X.columns:\n",
        "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# Instead of individual column conversion, convert the entire DataFrame\n",
        "X = X.astype(float) # This ensures all columns are of numeric type\n",
        "\n",
        "# Add a constant to the independent variables for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "# Now that all columns in X are numeric, the model should fit without error\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Display the regression summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "VEiVcVPWyurS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Fitness Goal and Dietary Preferences to find total spend per meal order\n",
        "fitness_goal_meal_spend = df4_cleaned.groupby(['Fitness Goal', 'Dietary Preferences'])['Average Spend per Meal Order'].sum().reset_index()\n",
        "\n",
        "# Sort by the highest spend per fitness goal and meal type\n",
        "fitness_goal_meal_spend = fitness_goal_meal_spend.sort_values(by='Average Spend per Meal Order', ascending=False)\n",
        "\n",
        "# Display the total spend by fitness goal and dietary preference\n",
        "print(\"Total Spend by Fitness Goal and Meal Type:\\n\", fitness_goal_meal_spend)\n",
        "\n",
        "# Visualize the total spend by fitness goal and meal type\n",
        "sns.barplot(data=fitness_goal_meal_spend, x='Dietary Preferences', y='Average Spend per Meal Order', hue='Fitness Goal')\n",
        "plt.title('Fitness Goal vs Dietary Preference Meal Spend')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Total Spend per Meal Order')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X3rMYR6wzIDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate Customer IDs\n",
        "duplicates = df1[df1.duplicated(subset=['Customer ID'], keep=False)]\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "missing_values = df1.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "\n",
        "\n",
        "# Check for missing values\n",
        "print(df1.isnull().sum())\n",
        "\n",
        "# Drop missing values or fill them\n",
        "df1 = df1.dropna()\n",
        "# Check for duplicate Customer IDs\n",
        "duplicates = df1[df1.duplicated(subset=['Customer ID'], keep=False)]\n",
        "\n",
        "# Print duplicate entries (if any)\n",
        "print(\"Duplicate Entries based on Customer ID:\\n\", duplicates)\n",
        "# Check for missing values in each column\n",
        "print(\"Missing values in each column:\\n\", df1.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values (if necessary)\n",
        "df1_cleaned = df1.dropna()\n",
        "\n"
      ],
      "metadata": {
        "id": "_7iOsLV8z3Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Fitness Goal and find the average hours at gym and gym membership length\n",
        "grouped_consumption = df1_cleaned.groupby(['Fitness Goal'])[['Hours at Gym (per week)', 'Gym Membership Length (years)']].mean().reset_index()\n",
        "\n",
        "# Display grouped summary\n",
        "print(\"Grouped Summary by Fitness Goal:\\n\", grouped_consumption)\n",
        "\n",
        "# Visualize the grouped hours at gym and membership length\n",
        "sns.barplot(data=grouped_consumption, x='Fitness Goal', y='Hours at Gym (per week)')\n",
        "plt.title('Average Hours at Gym by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Average Hours at Gym (per week)')\n",
        "plt.show()\n",
        "\n",
        "sns.barplot(data=grouped_consumption, x='Fitness Goal', y='Gym Membership Length (years)')\n",
        "plt.title('Average Gym Membership Length by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Average Gym Membership Length (years)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HcabmZmZ0ylt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables like 'Fitness Goal' into dummy variables for regression\n",
        "df1_encoded = pd.get_dummies(df1_cleaned, columns=['Fitness Goal'], drop_first=True)\n",
        "\n",
        "# Check the first few rows of the encoded data\n",
        "print(df1_encoded.head())\n",
        "# Define the dependent variable (y) and independent variables (X)\n",
        "X = df1_encoded.drop(columns=['Calorie Intake', 'Customer ID'])  # Adjust columns as needed\n",
        "y = df1_encoded['Calorie Intake']\n",
        "\n",
        "# Add a constant to the independent variables for the intercept\n",
        "X = sm.add_constant(X)"
      ],
      "metadata": {
        "id": "3rHds8Qv04SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables like 'Fitness Goal' into dummy variables for regression\n",
        "df1_encoded = pd.get_dummies(df1_cleaned, columns=['Fitness Goal'], drop_first=True)\n",
        "\n",
        "# Check the first few rows of the encoded data\n",
        "print(df1_encoded.head())\n",
        "# Define the dependent variable (y) and independent variables (X)\n",
        "X = df1_encoded.drop(columns=['Calorie Intake', 'Customer ID'])  # Adjust columns as needed\n",
        "y = df1_encoded['Calorie Intake']\n",
        "\n",
        "# Convert all columns in X to numeric, coerce errors to NaN\n",
        "for col in X.columns:\n",
        "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values after conversion\n",
        "X = X.dropna()\n",
        "y = y[X.index] # Align y with X after dropping rows\n",
        "\n",
        "# Add a constant to the independent variables for the intercept\n",
        "X = sm.add_constant(X)\n",
        "# Group by Fitness Goal to find the average hours spent at the gym\n",
        "most_hours_at_gym = df1_cleaned.groupby('Fitness Goal')['Hours at Gym (per week)'].mean().reset_index()\n",
        "\n",
        "# Sort by the highest average hours to find which fitness goal spends the most time at the gym\n",
        "most_hours_at_gym = most_hours_at_gym.sort_values(by='Hours at Gym (per week)', ascending=False)\n",
        "\n",
        "# Display the fitness goal with the most hours spent at the gym\n",
        "print(\"Most Hours at Gym by Fitness Goal:\\n\", most_hours_at_gym)\n",
        "\n",
        "# Visualize the most hours spent at the gym by fitness goal\n",
        "sns.barplot(data=most_hours_at_gym, x='Fitness Goal', y='Hours at Gym (per week)')\n",
        "plt.title('Most Hours Spent at Gym by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Hours at Gym (per week)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0hqkOJGH1D5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Fitness Goal to find the average gym membership length\n",
        "fitness_goal_membership_length = df1_cleaned.groupby('Fitness Goal')['Gym Membership Length (years)'].mean().reset_index()\n",
        "\n",
        "# Sort by the longest membership length to find which fitness goal has the longest gym membership\n",
        "fitness_goal_membership_length = fitness_goal_membership_length.sort_values(by='Gym Membership Length (years)', ascending=False)\n",
        "\n",
        "# Display the fitness goal with the longest gym membership length\n",
        "print(\"Longest Gym Membership Length by Fitness Goal:\\n\", fitness_goal_membership_length)\n",
        "\n",
        "# Visualize the gym membership length by fitness goal\n",
        "sns.barplot(data=fitness_goal_membership_length, x='Fitness Goal', y='Gym Membership Length (years)')\n",
        "plt.title('Gym Membership Length by Fitness Goal')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Gym Membership Length (years)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MTRuIloX1YOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAw8A5Rj62yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency # Import chi2_contingency\n",
        "\n",
        "# Step 1: Merge data from ChefsMeal, PulseGear, and CoreBoost with Flexfield on 'Customer ID'\n",
        "merged_df = pd.merge(df1, df4[['Customer ID', 'Average Spend per Meal Order']], on='Customer ID', how='left')\n",
        "merged_df = pd.merge(merged_df, df3[['Customer ID', 'Average Spend on Apparel ($/year)']], on='Customer ID', how='left')\n",
        "merged_df = pd.merge(merged_df, df2[['Customer ID', 'Preferred Sports Drink Type']], on='Customer ID', how='left')\n",
        "\n",
        "# Display the first few rows of the merged dataset to verify\n",
        "print(merged_df.head())\n",
        "\n",
        "# Step 2: Create contingency tables for Chi-Squared test\n",
        "# We will test the association between Fitness Goals (Gym Flexfield) and each business data (Meal, Apparel, Sports Drink)\n",
        "contingency_meal = pd.crosstab(merged_df['Fitness Goal'], merged_df['Average Spend per Meal Order'])\n",
        "contingency_apparel = pd.crosstab(merged_df['Fitness Goal'], merged_df['Average Spend on Apparel ($/year)'])\n",
        "contingency_drink = pd.crosstab(merged_df['Fitness Goal'], merged_df['Preferred Sports Drink Type'])\n",
        "\n",
        "# Perform the Chi-Squared test for each business\n",
        "chi2_meal, p_meal, dof_meal, expected_meal = chi2_contingency(contingency_meal)\n",
        "chi2_apparel, p_apparel, dof_apparel, expected_apparel = chi2_contingency(contingency_apparel)\n",
        "chi2_drink, p_drink, dof_drink, expected_drink = chi2_contingency(contingency_drink)\n",
        "\n",
        "# Step 3: Output the Chi-Squared results\n",
        "print(f\"ChefsMeal - Chi-Squared: {chi2_meal}, P-value: {p_meal}\")\n",
        "print(f\"PulseGear (Apparel) - Chi-Squared: {chi2_apparel}, P-value: {p_apparel}\")\n",
        "print(f\"CoreBoost (Sports Drink) - Chi-Squared: {chi2_drink}, P-value: {p_drink}\")\n",
        "\n",
        "# Step 4: Interpret Results\n",
        "# The business with the lowest P-value indicates the strongest association with Gym Flexfield attributes\n",
        "if p_meal < p_apparel and p_meal < p_drink:\n",
        "    print(\"ChefsMeal has the closest association with Gym Flexfield (focused on brand loyalty and customer retention).\")\n",
        "elif p_apparel < p_meal and p_apparel < p_drink:\n",
        "    print(\"PulseGear has the closest association with Gym Flexfield (focused on brand loyalty and customer retention).\")\n",
        "else:\n",
        "    print(\"CoreBoost has the closest association with Gym Flexfield (focused on brand loyalty and customer retention).\")"
      ],
      "metadata": {
        "id": "G9dAgdjo2i_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each membership year\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "dfr1 = pd.read_excel(\"/content/drive/My Drive/First-Byte/final/flexfield_fitness.xlsx\")\n",
        "\n",
        "membership_counts = dfr1['Gym Membership Length (years)'].value_counts().sort_index()\n",
        "\n",
        "# Display the counts\n",
        "print(membership_counts)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming `membership_counts` is already calculated as described above\n",
        "\n",
        "# Convert `membership_counts` to a DataFrame and sort by year for consistency\n",
        "membership_counts_df = membership_counts.reset_index()\n",
        "membership_counts_df.columns = ['Years', 'Count']\n",
        "membership_counts_df = membership_counts_df.sort_values('Years')\n",
        "\n",
        "# Calculate the yearly dropout rate as the percentage decrease in members year over year\n",
        "membership_counts_df['Dropout_Rate'] = membership_counts_df['Count'].pct_change() * -100\n",
        "\n",
        "# Since the first year has no previous data, it will have NaN as dropout rate. Let's drop it.\n",
        "yearly_dropout_rates = membership_counts_df['Dropout_Rate'].dropna()\n",
        "\n",
        "# Calculate the average dropout rate\n",
        "average_dropout_rate = yearly_dropout_rates.mean()\n",
        "\n",
        "print(\"Yearly Dropout Rates:\\n\", yearly_dropout_rates)\n",
        "print(f\"\\nAverage Dropout Rate: {average_dropout_rate:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFdSAK9tL94N",
        "outputId": "a2f12cf2-a5ac-4f1a-e2ab-14663ca4c4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Gym Membership Length (years)\n",
            "0     66\n",
            "1    304\n",
            "2     80\n",
            "3    103\n",
            "4    231\n",
            "5    100\n",
            "6     11\n",
            "7      2\n",
            "Name: count, dtype: int64\n",
            "Yearly Dropout Rates:\n",
            " 1   -360.606061\n",
            "2     73.684211\n",
            "3    -28.750000\n",
            "4   -124.271845\n",
            "5     56.709957\n",
            "6     89.000000\n",
            "7     81.818182\n",
            "Name: Dropout_Rate, dtype: float64\n",
            "\n",
            "Average Dropout Rate: -30.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z89-vX1FZG2H"
      }
    }
  ]
}